{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf4a4c46-cfaa-4504-b60a-c311e044a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def ensure_tor_is_running():\n",
    "    tor_process = None\n",
    "    for proc in psutil.process_iter(['name']):\n",
    "        if proc.info['name'] == 'tor':\n",
    "            tor_process = proc\n",
    "            break\n",
    "    \n",
    "    if tor_process is None:\n",
    "        print(\"Tor is not running. Starting Tor...\")\n",
    "        subprocess.Popen([\"/opt/homebrew/opt/tor/bin/tor\"])\n",
    "        time.sleep(10)  # Wait for Tor to start up\n",
    "        print(\"Tor should now be running.\")\n",
    "    else:\n",
    "        print(\"Tor is already running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c291427e-7815-4b41-980e-629a9c12a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tor is already running.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ensure_tor_is_running()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d28ef3c-3948-4799-b6f6-812ff3820359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 21:28:14,663 - INFO - Successfully connected through Tor.\n",
      "2024-10-02 21:28:38,887 - WARNING - Attempt 1 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=All%20Departments&ref=nb_sb_noss_1&page=1\n",
      "2024-10-02 21:29:09,732 - WARNING - Attempt 2 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=All%20Departments&ref=nb_sb_noss_1&page=1\n",
      "2024-10-02 21:29:14,595 - INFO - Scraping interrupted by user.\n",
      "2024-10-02 21:29:14,597 - INFO - Scraping process finished.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import csv\n",
    "from urllib.parse import quote\n",
    "import socks\n",
    "import socket\n",
    "from fake_useragent import UserAgent\n",
    "import cloudscraper\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class TorSession(requests.Session):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(TorSession, self).__init__(*args, **kwargs)\n",
    "        self.proxies = {\n",
    "            'http': 'socks5h://localhost:9050',\n",
    "            'https': 'socks5h://localhost:9050'\n",
    "        }\n",
    "\n",
    "def get_tor_session():\n",
    "    session = TorSession()\n",
    "    retry = Retry(total=5, backoff_factor=0.2, status_forcelist=[500, 502, 503, 504])\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def check_tor_connection():\n",
    "    session = get_tor_session()\n",
    "    try:\n",
    "        response = session.get('https://check.torproject.org/', timeout=30)\n",
    "        if 'Congratulations. This browser is configured to use Tor.' in response.text:\n",
    "            logging.info(\"Successfully connected through Tor.\")\n",
    "            return True\n",
    "        else:\n",
    "            logging.warning(\"Connected to the internet, but not through Tor.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error checking Tor connection: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "class AmazonScraper:\n",
    "    def __init__(self):\n",
    "        self.ua = UserAgent()\n",
    "        self.session = self.create_scraper()\n",
    "\n",
    "    def create_scraper(self):\n",
    "        scraper = cloudscraper.create_scraper(\n",
    "            browser={\n",
    "                'browser': 'chrome',\n",
    "                'platform': 'windows',\n",
    "                'desktop': True\n",
    "            },\n",
    "            delay=10,\n",
    "            interpreter='nodejs'\n",
    "        )\n",
    "        scraper.proxies = {\n",
    "            'http': 'socks5h://localhost:9050',\n",
    "            'https': 'socks5h://localhost:9050'\n",
    "        }\n",
    "        return scraper\n",
    "\n",
    "    def get_headers(self):\n",
    "        return {\n",
    "            'User-Agent': self.ua.random,\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Referer': 'https://www.amazon.co.uk/',\n",
    "            'DNT': '1',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "        }\n",
    "\n",
    "    def throttle_request(self):\n",
    "        time.sleep(random.uniform(10, 30))  \n",
    "\n",
    "    def make_request(self, url, max_retries=5):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                self.session.cookies.clear()  \n",
    "                headers = self.get_headers()\n",
    "                response = self.session.get(url, headers=headers, timeout=60)\n",
    "                response.raise_for_status()\n",
    "                return response\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logging.warning(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    logging.error(f\"Max retries reached. Unable to fetch {url}\")\n",
    "                    return None\n",
    "                self.session = self.create_scraper()  # Create a new session for a new Tor circuit\n",
    "                time.sleep((2 ** attempt) + random.random() * 30)  # Exponential backoff with added randomness\n",
    "\n",
    "    def scrape_category(self, category, max_products=100):\n",
    "        all_products = []\n",
    "        page = 1\n",
    "        encoded_category = quote(category)\n",
    "        base_url = f\"https://www.amazon.co.uk/s?k={encoded_category}&ref=nb_sb_noss_1\"\n",
    "        \n",
    "        while len(all_products) < max_products:\n",
    "            url = f\"{base_url}&page={page}\"\n",
    "            self.throttle_request()\n",
    "            \n",
    "            response = self.make_request(url)\n",
    "            if not response:\n",
    "                break\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            product_cards = soup.select('div[data-component-type=\"s-search-result\"]')\n",
    "            \n",
    "            if not product_cards:\n",
    "                logging.warning(f\"No product cards found on page {page} for {category}. This might be a captcha page.\")\n",
    "                break\n",
    "            \n",
    "            for card in product_cards:\n",
    "                if len(all_products) >= max_products:\n",
    "                    break\n",
    "                \n",
    "                product_data = self.extract_product_data(card, category)\n",
    "                all_products.append(product_data)\n",
    "                logging.info(f\"Scraped product {len(all_products)} for {category}: {product_data['title']}\")\n",
    "            \n",
    "            # Check if there's a next page\n",
    "            next_page = soup.select_one('a.s-pagination-next')\n",
    "            if not next_page:\n",
    "                break\n",
    "            \n",
    "            page += 1\n",
    "            self.session = self.create_scraper()  # This creates a new session for a new Tor circuit between pages \n",
    "\n",
    "        logging.info(f\"Scraped {len(all_products)} products from the category {category}.\")\n",
    "        return all_products\n",
    "\n",
    "    def extract_product_data(self, card, category):\n",
    "        product_data = {'category': category}\n",
    "        \n",
    "        # Extract title\n",
    "        title_elem = card.select_one('h2 a.a-link-normal')\n",
    "        product_data['title'] = title_elem.text.strip() if title_elem else None\n",
    "        \n",
    "        # Extract price\n",
    "        price_elem = card.select_one('span.a-price-whole')\n",
    "        product_data['price'] = price_elem.text.strip() if price_elem else None\n",
    "        \n",
    "        # Extract rating\n",
    "        rating_elem = card.select_one('span.a-icon-alt')\n",
    "        product_data['rating'] = rating_elem.text.split()[0] if rating_elem else None\n",
    "        \n",
    "        # Extract review count\n",
    "        review_count_elem = card.select_one('span.a-size-base.s-underline-text')\n",
    "        product_data['review_count'] = review_count_elem.text.strip() if review_count_elem else None\n",
    "        \n",
    "        return product_data\n",
    "\n",
    "def scrape_all_categories(categories):\n",
    "    scraper = AmazonScraper()\n",
    "    all_data = []\n",
    "\n",
    "    for category in categories:\n",
    "        if isinstance(category, list):\n",
    "            for subcategory in category:\n",
    "                products = scraper.scrape_category(f\"{category[0]} {subcategory}\", max_products=100)\n",
    "                all_data.extend(products)\n",
    "        else:\n",
    "            products = scraper.scrape_category(category, max_products=100)\n",
    "            all_data.extend(products)\n",
    "        \n",
    "        time.sleep(random.uniform(180, 300))  \n",
    "\n",
    "    return all_data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    if not data:\n",
    "        logging.warning(\"No data to save. CSV file will not be created.\")\n",
    "        return\n",
    "    \n",
    "    keys = data[0].keys()\n",
    "    try:\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(data)\n",
    "        logging.info(f\"Data successfully saved to {filename}\")\n",
    "    except IOError as e:\n",
    "        logging.error(f\"IOError occurred while saving data: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error occurred while saving data: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not check_tor_connection():\n",
    "        logging.error(\"Failed to connect through Tor. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "    categories = [\n",
    "        \"All Departments\", \"Apps & Games\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        all_products = scrape_all_categories(categories)\n",
    "        save_to_csv(all_products, 'amazon_products_TOR.csv')\n",
    "        logging.info(\"Scraping completed. Data saved to amazon_products_TOR.csv\")\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Scraping interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        logging.info(\"Scraping process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "118f275d-bdb0-4e20-9ab2-156be2650271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 22:28:20,387 - INFO - Successfully connected through Tor.\n",
      "2024-10-02 22:28:35,164 - WARNING - Attempt 1 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=All%20Departments&ref=nb_sb_noss_1&page=1\n",
      "2024-10-02 22:28:45,465 - INFO - Scraped product 1 for All Departments: None\n",
      "2024-10-02 22:28:45,466 - INFO - Scraped product 2 for All Departments: None\n",
      "2024-10-02 22:28:45,466 - INFO - Scraped product 3 for All Departments: None\n",
      "2024-10-02 22:28:45,467 - INFO - Scraped product 4 for All Departments: None\n",
      "2024-10-02 22:28:45,467 - INFO - Scraped product 5 for All Departments: None\n",
      "2024-10-02 22:28:45,468 - INFO - Scraped product 6 for All Departments: None\n",
      "2024-10-02 22:28:45,469 - INFO - Scraped product 7 for All Departments: None\n",
      "2024-10-02 22:28:45,469 - INFO - Scraped product 8 for All Departments: None\n",
      "2024-10-02 22:28:45,470 - INFO - Scraped product 9 for All Departments: None\n",
      "2024-10-02 22:28:45,471 - INFO - Scraped product 10 for All Departments: None\n",
      "2024-10-02 22:28:45,472 - INFO - Scraped product 11 for All Departments: None\n",
      "2024-10-02 22:28:45,472 - INFO - Scraped product 12 for All Departments: None\n",
      "2024-10-02 22:28:45,473 - INFO - Scraped product 13 for All Departments: None\n",
      "2024-10-02 22:28:45,473 - INFO - Scraped product 14 for All Departments: None\n",
      "2024-10-02 22:28:45,474 - INFO - Scraped product 15 for All Departments: None\n",
      "2024-10-02 22:28:45,474 - INFO - Scraped product 16 for All Departments: None\n",
      "2024-10-02 22:28:45,475 - INFO - Scraped product 17 for All Departments: None\n",
      "2024-10-02 22:28:45,475 - INFO - Scraped product 18 for All Departments: None\n",
      "2024-10-02 22:28:45,476 - INFO - Scraped product 19 for All Departments: None\n",
      "2024-10-02 22:28:45,476 - INFO - Scraped product 20 for All Departments: None\n",
      "2024-10-02 22:28:45,477 - INFO - Scraped product 21 for All Departments: None\n",
      "2024-10-02 22:28:45,477 - INFO - Scraped product 22 for All Departments: None\n",
      "2024-10-02 22:28:45,478 - INFO - Scraped product 23 for All Departments: None\n",
      "2024-10-02 22:28:45,478 - INFO - Scraped product 24 for All Departments: None\n",
      "2024-10-02 22:28:45,479 - INFO - Scraped product 25 for All Departments: None\n",
      "2024-10-02 22:28:45,483 - INFO - Scraped 25 products from the category All Departments.\n",
      "2024-10-02 22:30:43,630 - INFO - Scraped product 1 for Apps & Games: None\n",
      "2024-10-02 22:30:43,631 - INFO - Scraped product 2 for Apps & Games: None\n",
      "2024-10-02 22:30:43,632 - INFO - Scraped product 3 for Apps & Games: None\n",
      "2024-10-02 22:30:43,633 - INFO - Scraped product 4 for Apps & Games: None\n",
      "2024-10-02 22:30:43,634 - INFO - Scraped product 5 for Apps & Games: None\n",
      "2024-10-02 22:30:43,635 - INFO - Scraped product 6 for Apps & Games: None\n",
      "2024-10-02 22:30:43,635 - INFO - Scraped product 7 for Apps & Games: None\n",
      "2024-10-02 22:30:43,638 - INFO - Scraped product 8 for Apps & Games: None\n",
      "2024-10-02 22:30:43,638 - INFO - Scraped product 9 for Apps & Games: None\n",
      "2024-10-02 22:30:43,639 - INFO - Scraped product 10 for Apps & Games: None\n",
      "2024-10-02 22:30:43,640 - INFO - Scraped product 11 for Apps & Games: None\n",
      "2024-10-02 22:30:43,643 - INFO - Scraped product 12 for Apps & Games: None\n",
      "2024-10-02 22:30:43,644 - INFO - Scraped product 13 for Apps & Games: None\n",
      "2024-10-02 22:30:43,644 - INFO - Scraped product 14 for Apps & Games: None\n",
      "2024-10-02 22:30:43,645 - INFO - Scraped product 15 for Apps & Games: None\n",
      "2024-10-02 22:30:43,646 - INFO - Scraped product 16 for Apps & Games: None\n",
      "2024-10-02 22:30:43,646 - INFO - Scraped product 17 for Apps & Games: None\n",
      "2024-10-02 22:30:43,647 - INFO - Scraped product 18 for Apps & Games: None\n",
      "2024-10-02 22:30:43,647 - INFO - Scraped product 19 for Apps & Games: None\n",
      "2024-10-02 22:30:43,648 - INFO - Scraped product 20 for Apps & Games: None\n",
      "2024-10-02 22:30:43,652 - INFO - Scraped 20 products from the category Apps & Games.\n",
      "2024-10-02 22:31:50,639 - INFO - Data successfully saved to amazon_products_TOR.csv\n",
      "2024-10-02 22:31:50,641 - INFO - Scraping completed. Data saved to amazon_products_TOR.csv\n",
      "2024-10-02 22:31:50,641 - INFO - Scraping process finished.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import csv\n",
    "from urllib.parse import quote\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_tor_session():\n",
    "    session = requests.session()\n",
    "    session.proxies = {\n",
    "        'http': 'socks5h://localhost:9050',\n",
    "        'https': 'socks5h://localhost:9050'\n",
    "    }\n",
    "    return session\n",
    "\n",
    "def check_tor_connection():\n",
    "    session = get_tor_session()\n",
    "    try:\n",
    "        response = session.get('https://check.torproject.org/', timeout=30)\n",
    "        if 'Congratulations. This browser is configured to use Tor.' in response.text:\n",
    "            logging.info(\"Successfully connected through Tor.\")\n",
    "            return True\n",
    "        else:\n",
    "            logging.warning(\"Connected to the internet, but not through Tor.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error checking Tor connection: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "class AmazonScraper:\n",
    "    def __init__(self):\n",
    "        self.ua = UserAgent()\n",
    "        self.session = get_tor_session()\n",
    "\n",
    "    def get_headers(self):\n",
    "        return {\n",
    "            'User-Agent': self.ua.random,\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Referer': 'https://www.amazon.co.uk/',\n",
    "            'DNT': '1',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "        }\n",
    "\n",
    "    def throttle_request(self):\n",
    "        time.sleep(random.uniform(10, 20))\n",
    "\n",
    "    def make_request(self, url, max_retries=5):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                self.session.cookies.clear()\n",
    "                headers = self.get_headers()\n",
    "                response = self.session.get(url, headers=headers, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                return response\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logging.warning(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    logging.error(f\"Max retries reached. Unable to fetch {url}\")\n",
    "                    return None\n",
    "                self.session = get_tor_session()  # Get a new Tor session\n",
    "                time.sleep((2 ** attempt) + random.random() * 10)\n",
    "\n",
    "    def scrape_category(self, category, max_products=25):\n",
    "        all_products = []\n",
    "        page = 1\n",
    "        encoded_category = quote(category)\n",
    "        base_url = f\"https://www.amazon.co.uk/s?k={encoded_category}&ref=nb_sb_noss_1\"\n",
    "        \n",
    "        while len(all_products) < max_products:\n",
    "            url = f\"{base_url}&page={page}\"\n",
    "            self.throttle_request()\n",
    "            \n",
    "            response = self.make_request(url)\n",
    "            if not response:\n",
    "                break\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            product_cards = soup.select('div[data-component-type=\"s-search-result\"]')\n",
    "            \n",
    "            if not product_cards:\n",
    "                logging.warning(f\"No product cards found on page {page} for {category}. This might be a captcha page.\")\n",
    "                break\n",
    "            \n",
    "            for card in product_cards:\n",
    "                if len(all_products) >= max_products:\n",
    "                    break\n",
    "                \n",
    "                product_data = self.extract_product_data(card, category)\n",
    "                all_products.append(product_data)\n",
    "                logging.info(f\"Scraped product {len(all_products)} for {category}: {product_data['title']}\")\n",
    "            \n",
    "            next_page = soup.select_one('a.s-pagination-next')\n",
    "            if not next_page:\n",
    "                break\n",
    "            \n",
    "            page += 1\n",
    "            self.session = get_tor_session()  # Get a new Tor session between pages\n",
    "            time.sleep(random.uniform(30, 60))\n",
    "\n",
    "        logging.info(f\"Scraped {len(all_products)} products from the category {category}.\")\n",
    "        return all_products\n",
    "\n",
    "    def extract_product_data(self, card, category):\n",
    "        product_data = {'category': category}\n",
    "        \n",
    "        title_elem = card.select_one('h2 a.a-link-normal')\n",
    "        product_data['title'] = title_elem.text.strip() if title_elem else None\n",
    "        \n",
    "        price_elem = card.select_one('span.a-price-whole')\n",
    "        product_data['price'] = price_elem.text.strip() if price_elem else None\n",
    "        \n",
    "        rating_elem = card.select_one('span.a-icon-alt')\n",
    "        product_data['rating'] = rating_elem.text.split()[0] if rating_elem else None\n",
    "        \n",
    "        review_count_elem = card.select_one('span.a-size-base.s-underline-text')\n",
    "        product_data['review_count'] = review_count_elem.text.strip() if review_count_elem else None\n",
    "        \n",
    "        return product_data\n",
    "\n",
    "def scrape_all_categories(categories):\n",
    "    scraper = AmazonScraper()\n",
    "    all_data = []\n",
    "\n",
    "    for category in categories:\n",
    "        if isinstance(category, list):\n",
    "            for subcategory in category:\n",
    "                products = scraper.scrape_category(f\"{category[0]} {subcategory}\", max_products=25)\n",
    "                all_data.extend(products)\n",
    "        else:\n",
    "            products = scraper.scrape_category(category, max_products=25)\n",
    "            all_data.extend(products)\n",
    "        \n",
    "        time.sleep(random.uniform(60, 120))\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    if not data:\n",
    "        logging.warning(\"No data to save. CSV file will not be created.\")\n",
    "        return\n",
    "    \n",
    "    keys = data[0].keys()\n",
    "    try:\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(data)\n",
    "        logging.info(f\"Data successfully saved to {filename}\")\n",
    "    except IOError as e:\n",
    "        logging.error(f\"IOError occurred while saving data: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error occurred while saving data: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not check_tor_connection():\n",
    "        logging.error(\"Failed to connect through Tor. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "    categories = [\n",
    "        \"All Departments\", \"Apps & Games\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        all_products = scrape_all_categories(categories)\n",
    "        save_to_csv(all_products, 'amazon_products_TOR.csv')\n",
    "        logging.info(\"Scraping completed. Data saved to amazon_products_TOR.csv\")\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Scraping interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        logging.info(\"Scraping process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9290d524-50c9-425b-a29b-ceb186a077cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 23:35:05,909 - INFO - Connected through IP: 192.42.116.195\n",
      "2024-10-04 23:35:32,507 - WARNING - Attempt 1 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=1\n",
      "2024-10-04 23:35:37,303 - WARNING - Attempt 2 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=1\n",
      "2024-10-04 23:35:42,394 - WARNING - Attempt 3 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=1\n",
      "2024-10-04 23:35:50,612 - WARNING - Attempt 4 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=1\n",
      "2024-10-04 23:36:02,323 - WARNING - Attempt 5 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=1\n",
      "2024-10-04 23:36:24,463 - INFO - Accessed page through IP: 192.42.116.195\n",
      "2024-10-04 23:36:24,540 - INFO - Scraped product 1 for Apps & Games: None\n",
      "2024-10-04 23:36:24,541 - INFO - Scraped product 2 for Apps & Games: None\n",
      "2024-10-04 23:36:24,542 - INFO - Scraped product 3 for Apps & Games: None\n",
      "2024-10-04 23:36:24,543 - INFO - Scraped product 4 for Apps & Games: None\n",
      "2024-10-04 23:36:24,543 - INFO - Scraped product 5 for Apps & Games: None\n",
      "2024-10-04 23:36:24,544 - INFO - Scraped product 6 for Apps & Games: None\n",
      "2024-10-04 23:36:24,545 - INFO - Scraped product 7 for Apps & Games: None\n",
      "2024-10-04 23:36:24,545 - INFO - Scraped product 8 for Apps & Games: None\n",
      "2024-10-04 23:36:24,546 - INFO - Scraped product 9 for Apps & Games: None\n",
      "2024-10-04 23:36:24,546 - INFO - Scraped product 10 for Apps & Games: None\n",
      "2024-10-04 23:36:24,547 - INFO - Scraped product 11 for Apps & Games: None\n",
      "2024-10-04 23:36:24,548 - INFO - Scraped product 12 for Apps & Games: None\n",
      "2024-10-04 23:36:24,548 - INFO - Scraped product 13 for Apps & Games: None\n",
      "2024-10-04 23:36:24,549 - INFO - Scraped product 14 for Apps & Games: None\n",
      "2024-10-04 23:37:33,724 - WARNING - Attempt 1 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:37:35,821 - WARNING - Attempt 2 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:37:43,703 - WARNING - Attempt 3 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:37:55,931 - WARNING - Attempt 4 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:38:08,665 - WARNING - Attempt 5 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:38:31,838 - WARNING - Attempt 6 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:39:11,329 - WARNING - Attempt 7 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:40:20,961 - WARNING - Attempt 8 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:42:37,744 - WARNING - Attempt 9 failed: 503 Server Error: Service Unavailable for url: https://www.amazon.co.uk/s?k=Apps%20%26%20Games&ref=nb_sb_noss_1&page=2\n",
      "2024-10-04 23:46:56,199 - INFO - Accessed page through IP: 107.189.2.108\n",
      "2024-10-04 23:46:56,305 - INFO - Scraped product 15 for Apps & Games: P for Pizza Board Game: Family Travel Game Great for Adults and Kids | Perfect For Holidays and Camping, Compact and Travel Friendly, Beach Game\n",
      "2024-10-04 23:46:56,306 - INFO - Scraped product 16 for Apps & Games: Big Potato Chameleon Pictures: A hilarious, easy-to-learn imposter game for Kids, Teens and Adults | Family Game for 3-8 players, Age 8+\n",
      "2024-10-04 23:46:56,307 - INFO - Scraped product 17 for Apps & Games: Marvin's Magic - Kids Magic Set - Box Of Tricks, Amazing Magic Tricks For Kids - Magic Made Easy Range - Includes Magic Wand, Card Tricks + Much More - Suitable For Age 6+ - 225 Magic Tricks\n",
      "2024-10-04 23:46:56,307 - INFO - Scraped product 18 for Apps & Games: TOSY Flying Ring - 12 LEDs, Super Bright, Very Soft & Phosphorescent Rim, Auto Light Up, Safe, Waterproof, Lightweight frisbee, Cool Fun Christmas & Outdoor/Indoor Gift Toy for Boys/Girls/Kids\n",
      "2024-10-04 23:46:56,308 - INFO - Scraped product 19 for Apps & Games: Colorfy: Free Colouring Book for Adults - Best Colouring Apps by Fun Games For Free\n",
      "2024-10-04 23:46:56,308 - INFO - Scraped product 20 for Apps & Games: EA SPORTS FC 25 Standard Edition PCWin | Downloading Code EA App - Origin | VideoGame | English\n",
      "2024-10-04 23:46:56,308 - INFO - Scraped product 21 for Apps & Games: Pixelmon Go PE Game Mod\n",
      "2024-10-04 23:46:56,309 - INFO - Scraped product 22 for Apps & Games: Plunkett's Games, Apps & Social Media Industry Almanac 2024: Games, Apps & Social Media Industry Market Research, Statistics, Trends and Leading Companies\n",
      "2024-10-04 23:46:56,309 - INFO - Scraped product 23 for Apps & Games: Zen Word - Relax Puzzle Game\n",
      "2024-10-04 23:46:56,310 - INFO - Scraped product 24 for Apps & Games: Candy Craze - Match 3 Games Free and New 2023, Sweet Royal Sugar Matching for Adults on Kindle Fire\n",
      "2024-10-04 23:46:56,310 - INFO - Scraped product 25 for Apps & Games: YORKOO Magic Electronic Music Novelty Puzzle Game for Teens Kids\n",
      "2024-10-04 23:46:56,311 - INFO - Scraped product 26 for Apps & Games: Colourbrain Board Game: Award-Winning Simple Family Board Game | Reduced Packaging | Includes 20 Secret Questions | Fun Christmas Game for Families and Adults\n",
      "2024-10-04 23:46:56,312 - INFO - Scraped product 27 for Apps & Games: QUICKSTOP | Card Game for Family and Friends | Fast and Hilarious | 2-7 players | Party Game for Adults and Kids 10+ | 30 minutes Playing Time\n",
      "2024-10-04 23:46:56,312 - INFO - Scraped product 28 for Apps & Games: Big Potato OK Play: The Ultimate Tile Game - Kids Can Outsmart Adults | Fun, Strategic & Portable for 2-4 Players, Ideal Board Travel Game for Family Game Night\n",
      "2024-10-04 23:46:56,313 - INFO - Scraped product 29 for Apps & Games: Go Big or Go Home: The Hilarious, Fast Thinking Category Game | For 2+ Players Ages 12+\n",
      "2024-10-04 23:46:56,313 - INFO - Scraped product 30 for Apps & Games: LaiEr Golf Mat Chopping Game Training Aids Golf Hitting Mats Indoor/Outdoor Training | Comes with 2 60mm Rubber T Golf Training Mats\n",
      "2024-10-04 23:46:56,314 - INFO - Scraped product 31 for Apps & Games: QUIZTIMATE - The trivia game that keeps you guessing! - The hilarious 4-round quiz game that anyone can win, perfect for friends and family!\n",
      "2024-10-04 23:46:56,314 - INFO - Scraped product 32 for Apps & Games: Puzzle Potato - Philosopher's Stone - Escape Room Game - Wooden Puzzle Box - 3D Brain Teaser Puzzle - Treasure Box\n",
      "2024-10-04 23:46:56,315 - INFO - Scraped product 33 for Apps & Games: Preschool Learning Games For Toddlers, Nursery Rhymes, Kids Stories, Numbers & ABC Songs - KidloLand\n",
      "2024-10-04 23:46:56,315 - INFO - Scraped product 34 for Apps & Games: FUNKO GAMES Presents: Scream - The Game | Thrilling Mystery Horror Board Game with Interactive iOS/Android App | For 3-8 Players Ages 13+\n",
      "2024-10-04 23:46:56,315 - INFO - Scraped product 35 for Apps & Games: Exploding Kittens Original Edition - Hilarious Game for Family Game Night - Funny Card Games for Ages 7 and Up - 56 Cards - 2-5 Players - 15 Minutes of Play\n",
      "2024-10-04 23:46:56,316 - INFO - Scraped product 36 for Apps & Games: Idle Pizza Restaurant - Pizza Ready Business Empire Tycoon Game\n",
      "2024-10-04 23:46:56,316 - INFO - Scraped product 37 for Apps & Games: Magic Jigsaw Puzzles – Free best puzzle HD game for adults & kids with the biggest online jigsaw collection. Solve & explore! Collect the pieces & train your brain. Amazing photos & pictures!\n",
      "2024-10-04 23:46:56,316 - INFO - Scraped product 38 for Apps & Games: Google Play gift code - give the gift of games, apps and more (Email Delivery - UK Customers Only)\n",
      "2024-10-04 23:46:56,317 - INFO - Scraped product 39 for Apps & Games: Learn JavaFX Game and App Development: With FXGL 17\n",
      "2024-10-04 23:46:56,317 - INFO - Scraped product 40 for Apps & Games: TutoPLAY Best Kids Games - 100 in 1 App Pack\n",
      "2024-10-04 23:46:56,318 - INFO - Scraped product 41 for Apps & Games: Google Play gift code £10 - give the gift of games, apps and more (Email Delivery - UK Customers Only)\n",
      "2024-10-04 23:46:56,318 - INFO - Scraped product 42 for Apps & Games: Boxbollen Original with App, Used by Celebrities - MMA Gear Boxing Ball - Boxing Reflex Ball with Adjustable Strap - Interactive Boxball App Integration - 1 Pack\n",
      "2024-10-04 23:46:56,318 - INFO - Scraped product 43 for Apps & Games: Hot Wheels - Race Off Hot Car Wheels Mega Ramp Car Stunts Games\n",
      "2024-10-04 23:46:56,319 - INFO - Scraped product 44 for Apps & Games: Drawing Academy: Toddler colouring in animal games for girls and boys! Baby drawing apps for learning letters ABC and 123 numbers! Painting for toddlers! Educational games for 2, 3, 4, 5, 6 year olds!\n",
      "2024-10-04 23:46:56,319 - INFO - Scraped product 45 for Apps & Games: Miko My Companion Miko 3 : AI-Powered Smart Robot for Kids | STEM Learning & Educational Robot | Interactive Robo with Coding apps + Unlimited Games + programmable | For Kids 5-10 Years Old | Blue\n",
      "2024-10-04 23:46:56,320 - INFO - Scraped product 46 for Apps & Games: Preschool Games for 2-5 Year Olds - Kids Learning App for Toddlers With 650+ Educational Games\n",
      "2024-10-04 23:46:56,320 - INFO - Scraped product 47 for Apps & Games: Chat King - Chatting Master\n",
      "2024-10-04 23:46:56,320 - INFO - Scraped product 48 for Apps & Games: Libellud | Mysterium Board Game (Base Game) | Mystery Board Game | Cooperative Game for Adults and Kids | Fun for Family Game Night | Ages 10 and up | 2-7 Players | Average Playtime 45 Minutes\n",
      "2024-10-04 23:46:56,321 - INFO - Scraped product 49 for Apps & Games: The Trivia Game\n",
      "2024-10-04 23:46:56,321 - INFO - Scraped product 50 for Apps & Games: Solitaire\n",
      "2024-10-04 23:46:56,321 - INFO - Scraped 50 products from the category Apps & Games.\n",
      "2024-10-04 23:49:06,909 - INFO - Accessed page through IP: 107.189.2.108\n",
      "2024-10-04 23:49:07,231 - INFO - Scraped product 1 for Home & Kitchen: Firexo All in One Fire Extinguisher (2 Litre / 2 kg) - Multipurpose Extinguisher for ALL FIRES inc. Li-ion Battery Fires! - Safety & Emergency Equipment for Home, Kitchen, Fireplace, Grill, Caravan\n",
      "2024-10-04 23:49:07,231 - INFO - Scraped product 2 for Home & Kitchen: DIVCHI Pack of 10x 500ml Interior Dehumidifiers - for Stop Damp, Mildew, Mould Condensation Moisture Absorber Remover in Home Kitchen Wardrobe Bedroom Caravan Office Garage Bathroom, Basement\n",
      "2024-10-04 23:49:07,232 - INFO - Scraped product 3 for Home & Kitchen: Interior Dehumidifier Pack of 10 X 500ml Stop Damp,Mould Mildew & Condensation Trap Moisture Absorber Stop Damp, for Damp Smell Remover in Wardrobe, Home, Kitchen, Garage, Bedroom, Caravan, Office\n",
      "2024-10-04 23:49:07,233 - INFO - Scraped product 4 for Home & Kitchen: Firexo Mini - Multipurpose All-in-One Fire Extinguisher for Home, Kitchen, Car, Garage, Boat, Caravan, Campervan, Camping, Household Domestic Small Fire Extinguisher\n",
      "2024-10-04 23:49:07,233 - INFO - Scraped product 5 for Home & Kitchen: Kitchen Utensils Set - Non-Stick Heat Resistant Cooking Utensils Set - Spoons Turners Spatula Ladle Set - Kitchen Tools Gadgets Accessories (25 pcs Nylon Set - Black)\n",
      "2024-10-04 23:49:07,233 - INFO - Scraped product 6 for Home & Kitchen: HomeFashion Digital Kitchen Scales Food Scale with stainless steel Platform Electronic Cooking with Backlit LCD Display Multifunction for Home Office Use 5kg 1g 11lb\n",
      "2024-10-04 23:49:07,234 - INFO - Scraped product 7 for Home & Kitchen: ANBOXIT Coffee Station Organizer for Countertop, Coffee Bar Accessories and Organizer, Wooden Kitchen Counter Shelf, 2 Tier Coffee Condiment Storage, Coffee Caddy for Kitchen, Home, Office - Brown\n",
      "2024-10-04 23:49:07,234 - INFO - Scraped product 8 for Home & Kitchen: ACCUWEIGHT 201 Digital Kitchen Scales with Tempered Glass Platform Electronic Weighing Food Scale with Backlit LCD Display Multifunctional, for Office School Home Baking Cooking, 5kg/11lb\n",
      "2024-10-04 23:49:07,235 - INFO - Scraped product 9 for Home & Kitchen: Black Kitchen Roll Holder Under Cabinet,Stainless Steel Paper Towel Holder for Kitchen Self-Adhesive Wall Mounted Paper Towel Rack, Suitable for Pantry, Kitchen,Bathroom\n",
      "2024-10-04 23:49:07,235 - INFO - Scraped product 10 for Home & Kitchen: AIXPI Under Sink Storage Kitchen Organiser, Bathroom Storage 2 Tier Pull Out Kitchen Storage Cupboard Organiser Under Sink shelf, Home Organisation for Cabinet 2Pack\n",
      "2024-10-04 23:49:07,236 - INFO - Scraped product 11 for Home & Kitchen: nuoshen 3 Pieces Premium Adhesive Round Towel Holder, Adhesive Towel Hooks Round Wall Mount Hook Tea Towel Holder for Bathroom, Kitchen and Home, No Drilling Required\n",
      "2024-10-04 23:49:07,236 - INFO - Scraped product 12 for Home & Kitchen: simplywire – Sink Tidy/Caddy – Kitchen Sink Organiser – Removable Drip Tray – Non-Slip - Grey & White\n",
      "2024-10-04 23:49:07,237 - INFO - Scraped product 13 for Home & Kitchen: nuoshen 3 Pieces Premium Adhesive Round Towel Holder, Adhesive Towel Hooks Round Wall Mount Hook Tea Towel Holder for Bathroom, Kitchen and Home, No Drilling Required\n",
      "2024-10-04 23:49:07,237 - INFO - Scraped product 14 for Home & Kitchen: SPACEKEEPER Storage Trolley 3-Tier Slim Storage Cart Slide Out Rolling Utility Cart Mobile Shelving Unit Trolley Organizer Cart for Kitchen Bathroom Laundry Office, Plastic,White\n",
      "2024-10-04 23:49:07,238 - INFO - Scraped product 15 for Home & Kitchen: Zhtulck Bag Clips for Food Storage, 2 Sizes - 12 Pcs Food Bag Clips for Food Storage, Reusable Food Clips, Food Clips Bag Sealing Clips for Snacks Coffee Home Kitchen, 4 Color\n",
      "2024-10-04 23:49:07,238 - INFO - Scraped product 16 for Home & Kitchen: Typhur InstaProbe Meat Thermometer Digital - 0.5s Instant Read Cooking Thermometer, NIST Certified ±0.3℃ Accurate, Large OLED Display, IP67 Waterproof for Grill BBQ Smoker Candy Liquid Home Kitchen\n",
      "2024-10-04 23:49:07,239 - INFO - Scraped product 17 for Home & Kitchen: Tower T81522B Essentials Kitchen Knife Set, Stone-Coated with Stainless Steel Blades, Black, 6-Piece, 9 cm\n",
      "2024-10-04 23:49:07,239 - INFO - Scraped product 18 for Home & Kitchen: Kitchen Gizmo Snap N' Strain - Silicone Clip-On Colander, Heat Resistant Drainer for Vegetables and Pasta Noodles, Kitchen Gadgets for Bowl, Pots, and Pans - Essential Home Cooking Tools - Grey\n",
      "2024-10-04 23:49:07,239 - INFO - Scraped product 19 for Home & Kitchen: GEMWON Under Sink Storage Kitchen Organiser, 2 Tier Sliding Kitchen Storage Under Sink shelf, Multi-Purpose Organisation for Kitchen Bathroom, Bottom Slide Out Basket Black 2Piece\n",
      "2024-10-04 23:49:07,240 - INFO - Scraped product 20 for Home & Kitchen: AIDEA Microfibre Cloth 12 Pack,Reusable Kitchen Microfibre Cleaning Towels Dish Cloths,Lint Free Washable Duster Rags Cloth for Home,Windows,Car,Motorbike,30 x 30 cm\n",
      "2024-10-04 23:49:07,240 - INFO - Scraped product 21 for Home & Kitchen: Wall Clock Silent & Non Ticking Modern Quartz 9\"- Battery Operated Digital Quiet Sweep Office/home/school/Kitchen Decor Clocks\n",
      "2024-10-04 23:49:07,241 - INFO - Scraped product 22 for Home & Kitchen: MR.SIGA Microfibre Cleaning Cloth, All-Purpose Surface Microfibre Towel, Streak Free Reusable Kitchen Towel for Kitchen, House,Bathrooms, Car, Pack of 12, Sky Blue, 32 x 32 cm(12.6 x 12.6 inch)…\n",
      "2024-10-04 23:49:07,242 - INFO - Scraped product 23 for Home & Kitchen: GEPUTING Wall Hooks 15kg(MAX) Heavy Duty Self Adhesive Hooks 10 Pack,Waterproof and Oilproof,Transparent Reusable Seamless Hooks Strong,Suitable for Bathroom Kitchen\n",
      "2024-10-04 23:49:07,242 - INFO - Scraped product 24 for Home & Kitchen: UZIMOO Handheld Vacuum Cordless, 12000Pa Powerful Car Vacuum Cleaner, Mini Hand Vacuum Cleaner, Portable Lightweight USB Rechargeable Hand held Vacuum Cleaner for Pet Hair, Car, Home, Office, Kitchen\n",
      "2024-10-04 23:49:07,242 - INFO - Scraped product 25 for Home & Kitchen: LYINUR 2Pcs Crevice Cleaning Brush, Gap Cleaning Brush Groove Scrubbing Brushes, Hard Bristle Cleaner Brush, Window Door Bathroom Track Slots Gap Thin Cleaning Tool for Home Kitchen Small Spaces\n",
      "2024-10-04 23:49:07,243 - INFO - Scraped product 26 for Home & Kitchen: Pipishell Floating Shelves Wall Mounted Shelf, Paulownia Wood Wall Shelves, Wooden Shelves Set of 3 for Bedroom, Bathroom, Living Room, Kitchen, Home Office, Laundry room,etc (rustic)\n",
      "2024-10-04 23:49:07,244 - INFO - Scraped product 27 for Home & Kitchen: 12\" Wall Clock Silent & Large Wall Clocks for Living Room Office Home Kitchen Decor Modern Style & Easy to Read - Rose Gold &Black\n",
      "2024-10-04 23:49:07,244 - INFO - Scraped product 28 for Home & Kitchen: Spray Mop for Cleaning Floors, HOMTOYOU Microfiber Floor Mop Dry Wet Mop with 2 Refillable Bottles and 4 Washable Pads 360° Rotatable Cleaning Mop for Home Kitchen Hardwood Laminate Wood Tiles\n",
      "2024-10-04 23:49:07,244 - INFO - Scraped product 29 for Home & Kitchen: Samhita Acacia Wood Heart Shape Coaster Set of 4 With Iron Holder for Coffee Table Décor Housewarming Gift New Home Kitchen Décor (10.16cm x 10.16cm x 1.27cm)\n",
      "2024-10-04 23:49:07,245 - INFO - Scraped product 30 for Home & Kitchen: Lifewit Cutlery Drawer Organiser, Expandable Utensil Tray for Kitchen, Adjustable Silverware and Flatware Holder, Compact Plastic Storage for Spoons Forks Knives, Large, Black\n",
      "2024-10-04 23:49:07,246 - INFO - Scraped product 31 for Home & Kitchen: Pink Double Oven Gloves | Maximum Heat Resistant Protection | Double Oven Mitt With Silicone Non-slip Design | Machine Washable Oven Glove Home & Kitchen Accessories.\n",
      "2024-10-04 23:49:07,246 - INFO - Scraped product 32 for Home & Kitchen: Sterling Ventures 60 Litres Premium Plastic Swing Bin for Home and Kitchen Rubbish Waste (Black)\n",
      "2024-10-04 23:49:07,247 - INFO - Scraped product 33 for Home & Kitchen: Home Hero 33pcs Silicone Kitchen Utensils Set - Non-Stick Heat Resistant Cooking Utensils Set - Spoons Turners Spatula Ladle Set - Kitchen Tools Gadgets Accessories\n",
      "2024-10-04 23:49:07,247 - INFO - Scraped product 34 for Home & Kitchen: Kitchen Utensils Set, 12 pcs Non-Stick Silicone Cooking Kitchen Utensils Spatula Set with Holder, Cooking Spatula Turner Heat Resistant Tools with Wooden Handle (Black Grey)\n",
      "2024-10-04 23:49:07,247 - INFO - Scraped product 35 for Home & Kitchen: Firexo All in One Fire Extinguisher (2 Litre / 2 kg) - Multipurpose Extinguisher for ALL FIRES inc. Li-ion Battery Fires! - Safety & Emergency Equipment for Home, Kitchen, Fireplace, Grill, Caravan\n",
      "2024-10-04 23:49:07,248 - INFO - Scraped product 36 for Home & Kitchen: G.a HOMEFAVOR 2-Tier Bamboo Fruit Basket Bowl Holder, Bread Vegetables Storage Stand for Kitchen Countertop, Snacks Rack in Home Kitchen and Office\n",
      "2024-10-04 23:49:07,248 - INFO - Scraped product 37 for Home & Kitchen: SonicScrubber Household Cleaning Brush Heads - Electric Scrubbing Brush Accessory - Home, Kitchen & Bathroom - Removes Mould & Cleans Grout (Household System)\n",
      "2024-10-04 23:49:07,249 - INFO - Scraped product 38 for Home & Kitchen: Blackmoor 66929 5-Piece Knife Set/Comes with Freestanding Storage Block/Stainless Steel Knives/Non-Stick Black Marble Coating/Easy Clean/Modern & Stylish Kitchen Accessory\n",
      "2024-10-04 23:49:07,249 - INFO - Scraped product 39 for Home & Kitchen: SXhyf Cleaning Brush - Hard Bristle Crevice Cleaning Brush UK, Multifunctional Gap Cleaning Scrub Brush, Grout Brush, Cleaning Products for Household Use, Home, Kitchen, Bathroom, Window, Vehicle\n",
      "2024-10-04 23:49:07,250 - INFO - Scraped product 40 for Home & Kitchen: Pipishell Floating Shelves with Wire Strorage Basket, Paulownia Wood Bathroom Shelves for Home Organization & Wall Decor, Bathroom/Kitchen/Living Room/Office Shelves, Set of 3+1, Natural\n",
      "2024-10-04 23:49:07,250 - INFO - Scraped product 41 for Home & Kitchen: Wall Clock Silent & Non Ticking Modern Quartz 9\"- Battery Operated Digital Quiet Sweep Office/home/school/Kitchen Decor Clocks(Silver)\n",
      "2024-10-04 23:49:07,250 - INFO - Scraped product 42 for Home & Kitchen: Kitchen Roll Holder, Kitchen Paper Rack Wall Mounted, Toilet Roll Holder,Napkins Storage Rack Holder Under Cabinet, Paper Towel Roll Holder Self Adhesive No Drilling Required (White)\n",
      "2024-10-04 23:49:07,251 - INFO - Scraped product 43 for Home & Kitchen: Elfranso Tea Towels – 100% Cotton Kitchen Tea towels- Pack of 5 and Absorbent Tea Towels set, 70 x 50 cm Towels (Grey)\n",
      "2024-10-04 23:49:07,251 - INFO - Scraped product 44 for Home & Kitchen: DUMAO 12 in 1 Vegetable Chopper, Multifunctional Mandoline Slicer Dicer Household Kitchen Manual Julienne Grater Cutter for Onion, Garlic, Carrot, Potato, Tomato, Fruit, Salad\n",
      "2024-10-04 23:49:07,252 - INFO - Scraped product 45 for Home & Kitchen: Cosi Home 12L/Day Dehumidifier - Low Energy Compressor Dehumidifier with 2.5L Water Tank for Damp, Mould, Condensation - Moisture Remover for Home, Kitchen, Bathroom, Office, Garage\n",
      "2024-10-04 23:49:07,252 - INFO - Scraped product 46 for Home & Kitchen: Multi Purpose Powder Fire Extinguisher – Ready to Use in Seconds – 1kg ABC Fire Extinguisher for Home & Kitchen Use – 5 Year Guarantee – Firechief Travel Extinguisher for Cars, Campervans & Caravans\n",
      "2024-10-04 23:49:07,252 - INFO - Scraped product 47 for Home & Kitchen: Silicone Utensil Holder with Drip Pad for Multiple Utensils - Heat-Resistant - BPA-Free Spoon Rest for Kitchen & Stove Top - Utensil Holder - Zulay\n",
      "2024-10-04 23:49:07,253 - INFO - Scraped product 48 for Home & Kitchen: Vtopmart 60 Pack Drawer Organiser, 4-Size Clear Plastic Drawer Organiser Bins Containers for Bathroom and Vanity Storage, Home Organization for Makeup, Kitchen Utensils\n",
      "2024-10-04 23:49:07,253 - INFO - Scraped product 49 for Home & Kitchen: Pro Breeze Dehumidifier 1500ml Portable Air Dehumidifier for Damp, Mould, Moisture in Home, Kitchen, Bedroom, Caravan, Office, Garage, Bathroom, Basement\n",
      "2024-10-04 23:49:07,254 - INFO - Scraped product 50 for Home & Kitchen: Pro Breeze® 1500ml Premium Dehumidifier for Damp, Mould, Moisture in Home, Kitchen, Bedroom, Caravan, Office, Garage\n",
      "2024-10-04 23:49:38,608 - INFO - Scraped 50 products from the category Home & Kitchen.\n",
      "2024-10-04 23:51:05,034 - INFO - Total pages accessed: 3\n",
      "2024-10-04 23:51:05,040 - INFO - Average page size: 969.90 KB\n",
      "2024-10-04 23:51:05,051 - INFO - Data successfully saved to amazon_products_TOR.csv\n",
      "2024-10-04 23:51:05,052 - INFO - Scraping completed. Data saved to amazon_products_TOR.csv\n",
      "2024-10-04 23:51:05,053 - INFO - Scraping process finished.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import csv\n",
    "from urllib.parse import quote\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_tor_session():\n",
    "    session = requests.session()\n",
    "    session.proxies = {\n",
    "        'http': 'socks5h://localhost:9050',\n",
    "        'https': 'socks5h://localhost:9050'\n",
    "    }\n",
    "    return session\n",
    "\n",
    "def check_tor_connection():\n",
    "    session = get_tor_session()\n",
    "    try:\n",
    "        response = session.get('https://api.ipify.org?format=json', timeout=30)\n",
    "        ip = response.json()['ip']\n",
    "        logging.info(f\"Connected through IP: {ip}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error checking Tor connection: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "class AmazonScraper:\n",
    "    def __init__(self):\n",
    "        self.ua = UserAgent()\n",
    "        self.session = get_tor_session()\n",
    "        self.pages_accessed = 0\n",
    "        self.total_page_size = 0\n",
    "\n",
    "    def get_headers(self):\n",
    "        return {\n",
    "            'User-Agent': self.ua.random,\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Referer': 'https://www.amazon.co.uk/',\n",
    "            'DNT': '1',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "        }\n",
    "\n",
    "    def throttle_request(self):\n",
    "        time.sleep(random.uniform(10, 20))\n",
    "\n",
    "    def make_request(self, url, max_retries=10):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                self.session.cookies.clear()\n",
    "                headers = self.get_headers()\n",
    "                response = self.session.get(url, headers=headers, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                self.pages_accessed += 1\n",
    "                self.total_page_size += len(response.content)\n",
    "                logging.info(f\"Accessed page through IP: {self.session.get('https://api.ipify.org?format=json').json()['ip']}\")\n",
    "                return response\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logging.warning(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    logging.error(f\"Max retries reached. Unable to fetch {url}\")\n",
    "                    return None\n",
    "                self.session = get_tor_session()  # Get a new Tor session\n",
    "                time.sleep((2 ** attempt) + random.random() * 10)\n",
    "\n",
    "    def scrape_category(self, category, max_products=50, max_pages=2):\n",
    "        all_products = []\n",
    "        page = 1\n",
    "        encoded_category = quote(category)\n",
    "        base_url = f\"https://www.amazon.co.uk/s?k={encoded_category}&ref=nb_sb_noss_1\"\n",
    "        \n",
    "        while len(all_products) < max_products and page <= max_pages:\n",
    "            url = f\"{base_url}&page={page}\"\n",
    "            self.throttle_request()\n",
    "            \n",
    "            response = self.make_request(url)\n",
    "            if not response:\n",
    "                break\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            product_cards = soup.select('div[data-component-type=\"s-search-result\"]')\n",
    "            \n",
    "            if not product_cards:\n",
    "                logging.warning(f\"No product cards found on page {page} for {category}. This might be a captcha page.\")\n",
    "                break\n",
    "            \n",
    "            for card in product_cards:\n",
    "                if len(all_products) >= max_products:\n",
    "                    break\n",
    "                \n",
    "                product_data = self.extract_product_data(card, category)\n",
    "                if product_data:\n",
    "                    all_products.append(product_data)\n",
    "                    logging.info(f\"Scraped product {len(all_products)} for {category}: {product_data['title']}\")\n",
    "            \n",
    "            page += 1\n",
    "            if page <= max_pages:\n",
    "                self.session = get_tor_session()  # Get a new Tor session between pages\n",
    "                time.sleep(random.uniform(30, 60))\n",
    "\n",
    "        logging.info(f\"Scraped {len(all_products)} products from the category {category}.\")\n",
    "        return all_products\n",
    "\n",
    "    def extract_product_data(self, card, category):\n",
    "        try:\n",
    "            asin = card.get('data-asin')\n",
    "            title_elem = card.select_one('h2 a.a-link-normal')\n",
    "            title = title_elem.text.strip() if title_elem else None\n",
    "            url = f\"https://www.amazon.co.uk{title_elem['href']}\" if title_elem else None\n",
    "            \n",
    "            price_elem = card.select_one('span.a-price-whole')\n",
    "            price = float(price_elem.text.replace(',', '').strip()) if price_elem else None\n",
    "            \n",
    "            rating_elem = card.select_one('span.a-icon-alt')\n",
    "            rating = float(rating_elem.text.split()[0]) if rating_elem else None\n",
    "            \n",
    "            review_count_elem = card.select_one('span.a-size-base.s-underline-text')\n",
    "            review_count = int(review_count_elem.text.replace(',', '').strip()) if review_count_elem else None\n",
    "            \n",
    "            image_elem = card.select_one('img.s-image')\n",
    "            image = image_elem['src'] if image_elem else None\n",
    "\n",
    "            # Extract Best Sellers Rank\n",
    "            bsr_elem = card.select_one('th:-soup-contains(\"Best Sellers Rank\")')\n",
    "            bsr = []\n",
    "            if bsr_elem:\n",
    "                bsr_text = bsr_elem.find_next('td').text.strip()\n",
    "                ranks = bsr_text.split('\\n')\n",
    "                for rank in ranks:\n",
    "                    rank = rank.strip()\n",
    "                    if rank:\n",
    "                        match = re.search(r'#([\\d,]+)\\s+in\\s+(.+?)\\s*(\\(.*\\))?$', rank)\n",
    "                        if match:\n",
    "                            rank_num, category_name = match.group(1), match.group(2)\n",
    "                            bsr.append({\n",
    "                                'rank': int(rank_num.replace(',', '')),\n",
    "                                'category': category_name.strip()\n",
    "                            })\n",
    "\n",
    "            return {\n",
    "                'asin': asin,\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'rating': rating,\n",
    "                'review_count': review_count,\n",
    "                'category': category,\n",
    "                'url': url,\n",
    "                'image': image,\n",
    "                'best_sellers_rank': bsr,\n",
    "                'scraped_at': int(time.time() * 1000)  # Current timestamp in milliseconds\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extracting product data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def scrape_all_categories(categories):\n",
    "    scraper = AmazonScraper()\n",
    "    all_data = []\n",
    "\n",
    "    for category in categories:\n",
    "        if isinstance(category, list):\n",
    "            for subcategory in category:\n",
    "                products = scraper.scrape_category(f\"{category[0]} {subcategory}\", max_products=50, max_pages=2)\n",
    "                all_data.extend(products)\n",
    "        else:\n",
    "            products = scraper.scrape_category(category, max_products=50, max_pages=2)\n",
    "            all_data.extend(products)\n",
    "        \n",
    "        time.sleep(random.uniform(60, 120))\n",
    "\n",
    "    logging.info(f\"Total pages accessed: {scraper.pages_accessed}\")\n",
    "    logging.info(f\"Average page size: {scraper.total_page_size / scraper.pages_accessed / 1024:.2f} KB\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    if not data:\n",
    "        logging.warning(\"No data to save. CSV file will not be created.\")\n",
    "        return\n",
    "    \n",
    "    keys = data[0].keys()\n",
    "    try:\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(data)\n",
    "        logging.info(f\"Data successfully saved to {filename}\")\n",
    "    except IOError as e:\n",
    "        logging.error(f\"IOError occurred while saving data: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error occurred while saving data: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not check_tor_connection():\n",
    "        logging.error(\"Failed to connect through Tor. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "    categories = [\n",
    "        \"Apps & Games\", \"Home & Kitchen\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        all_products = scrape_all_categories(categories)\n",
    "        save_to_csv(all_products, 'amazon_products_TOR.csv')\n",
    "        logging.info(\"Scraping completed. Data saved to amazon_products_TOR.csv\")\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Scraping interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        logging.info(\"Scraping process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3f86b-09f0-4ebb-8376-cd68c59b1a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
